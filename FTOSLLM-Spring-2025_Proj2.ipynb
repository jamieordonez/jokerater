{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a487d5b-8b01-4b03-ad78-72f11681bf5f",
   "metadata": {},
   "source": [
    "# Project 2: Supvervised Learning\n",
    "\n",
    "## Total Points: 25\n",
    "\n",
    "### Overview\n",
    "In this project, you will **fine-tune an autoregressive language model (e.g., GPT-style) on a domain-specific**, labeled dataset using Parameter-Efficient Fine-Tuning (PEFT) techniques such as LoRA or adapters. The objective is to gain hands-on experience with preparing supervised data, applying PEFT to minimize training overhead, and evaluating the model’s performance on a task like text classification, summarization, or instruction following. You will compare the model's performance before and after fine-tuning using metrics such as accuracy, BLEU, or perplexity, depending on the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c856b-d89f-4f62-8cc3-357bfc2e1a8c",
   "metadata": {},
   "source": [
    "### 1. Identify the task and labeled datset\n",
    "- Choose a supervised learning task such as text classification, summarization, question answering, or instruction following, preferably within a specific domain (e.g., legal, medical, finance, science, etc.).\n",
    "\n",
    "- Select a labeled dataset appropriate for your task — one that includes both inputs and target outputs (e.g., prompts and responses, questions and answers, or documents and labels).\n",
    "\n",
    "- Make sure the dataset is:\n",
    "* Relevant to your chosen domain and task\n",
    "\n",
    "* Small enough to fine-tune efficiently (especially with PEFT), but large enough to produce meaningful improvements\n",
    "\n",
    "* You may need to experiment with dataset size or sampling to find a good balance between training time and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71351d2c-1406-48a8-af98-417d47a45944",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Process Your Data\n",
    "- Clean and preprocess the dataset to be suitable for an SL.\n",
    "- Convert the dataset into a format compatible with your training pipeline. \n",
    "- Consider preprocessing your data to improve training quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec2026-c5d0-4bb1-871f-1e527df561da",
   "metadata": {},
   "source": [
    "### 3. Baseline Measurement\n",
    "* Before fine-tuning, evaluate the performance of a pretrained autoregressive language model on your supervised task.\n",
    "\n",
    "* Use your labeled dataset in its original input-output format (e.g., prompt → response, input → label).\n",
    "\n",
    "* Measure how well the model performs without fine-tuning, using metrics appropriate for your task:\n",
    "\n",
    "* Accuracy, F1-score for classification\n",
    "\n",
    "* BLEU, ROUGE, or exact match for generation or QA\n",
    "\n",
    "\n",
    "* This will serve as your baseline for comparing performance after PEFT fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca68bf68-c8dc-49e7-9adc-63b6c28204df",
   "metadata": {},
   "source": [
    "### 4. Fine-Tune a AR model using PEFT\n",
    "* Fine-tune a pretrained autoregressive language model on your domain-specific, labeled dataset using Parameter-Efficient Fine-Tuning (PEFT) with LoRA (Low-Rank Adaptation).\n",
    "\n",
    "* Use a PEFT framework such as the Hugging Face peft library to integrate LoRA into your training pipeline.\n",
    "\n",
    "* LoRA modifies only a small subset of the model's parameters, allowing for efficient training even on limited hardware.\n",
    "\n",
    "* Implement a training loop or use tools like Trainer or accelerate for easier setup.\n",
    "\n",
    "* After training, save the LoRA adapter weights for reuse or evaluation — you can later merge them with the base model if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d6bcc8-39a5-4101-b30f-dd6b7c73b3d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5. Remeasure the Fine-Tuned Model\n",
    "* Evaluate the performance of your fine-tuned autoregressive model (now updated using LoRA) on the same supervised task and dataset used for the baseline.\n",
    "\n",
    "* Use the same evaluation metric as before (e.g., accuracy, BLEU, ROUGE, or perplexity, depending on the task).\n",
    "\n",
    "* Compare the results with the baseline measurement to assess the impact of fine-tuning.\n",
    "\n",
    "* Analyze whether the model has improved in task performance, and consider potential areas for further tuning or data refinement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a375a5-a554-4bad-88bc-0fce4c0ef74c",
   "metadata": {},
   "source": [
    "### 7. Organize & Summarize Results\n",
    "- Present your results in a structured format.\n",
    "- Compare the performance of the pre-trained and fine-tuned models.\n",
    "- Discuss key takeaways from the fine-tuning process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eadf69-2cda-4b25-a5e6-c134601bf012",
   "metadata": {},
   "source": [
    "## Hints & Tips\n",
    "- **Use Generative Models**: Make use of tools like chatgpt, claude to help you brainstorm, etc.\n",
    "- **Focus on Learning**: The goal is to understand MLM fine-tuning rather than achieving the best possible score. So focus on the process and not results\n",
    "- **Experiment & Analyze**: Try different settings and analyze their impact."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
